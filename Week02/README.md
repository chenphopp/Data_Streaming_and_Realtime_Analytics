# Getting started with Kafka

In this workshop, you will learn how Apache Kafka works and how you can use it to build applications that react to events as they happen. We demonstrate how you can use Kafka as an event streaming platform. We cover the key concepts of Kafka and take a look at the components of the Kafka platform.

## [Part 1 - Setup and Prerequisites](./part1/README.md)

The first part gives an overview of the Kafka platform. It covers the main use cases for Kafka. It also contains the prerequisites for the workshop.

## [Part 2 - Sending and consuming messages](./part2/README.md)

The second part covers the most basic concepts of Apache Kafka such as topics, partitions, and the Producer and Consumer clients.

## [Part 3 - Integrating data with Kafka Connect](./part3/README.md)

The third part explains how existing systems can be connected to Kafka using Kafka Connect. Using built-in connectors, we will see how data can be imported into Kafka.

## [Part 4 - Processing data with Kafka Streams](./part4/README.md)

The fourth part introduces Kafka Streams and explains its data processing capabilities. It explores the `WordCountDemo` sample application by running it and detailing its processing logic.

## Good resource for Docker

Docker: https://betterprogramming.pub/a-simple-apache-kafka-cluster-with-docker-kafdrop-and-python-cf45ab99e2b9


# New 1/2564 (Use Kafka on AWS (MKS))
